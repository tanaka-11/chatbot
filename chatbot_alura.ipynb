{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP9WSmFQxkCYjC22uLFBVg4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanaka-11/chatbot/blob/main/chatbot_alura.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Instalando Inteligencia Artificial da Google**"
      ],
      "metadata": {
        "id": "OLkJHRamRl3R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "G0W6RssfQ959"
      },
      "outputs": [],
      "source": [
        "# Instalando o SDK do Google\n",
        "!pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Configurando API Key**"
      ],
      "metadata": {
        "id": "90BjDHHnR5xM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configurações iniciais\n",
        "\n",
        "# Importação com apelido\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "api_key = userdata.get(\"SECRET_KEY\")\n",
        "\n",
        "\n",
        "# Configuração da API Key\n",
        "genai.configure(api_key=api_key)"
      ],
      "metadata": {
        "id": "gRQ21CP9RvvK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Listando modelos disponiveis**"
      ],
      "metadata": {
        "id": "GviBRnfBSKhs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Listando os modelos disponíveis\n",
        "\n",
        "# Loop de modelos disponiveis do gemini\n",
        "for modelo in genai.list_models():\n",
        "  # Condicional para verificar os modelos\n",
        "  if 'generateContent' in modelo.supported_generation_methods:\n",
        "    # Mostrando nome dos modelos\n",
        "    print(modelo.name)"
      ],
      "metadata": {
        "id": "2PLn27GQSQld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Configurações de parametros**"
      ],
      "metadata": {
        "id": "l_9taTkkU7Ld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# candidate_count = Numero de opções da resposta\n",
        "# temperature = Criatividade na resposta do chatbot de 0 a 1, sendo 1 mais criativo e 0 mais preciso\n",
        "\n",
        "generation_config = {\n",
        "  \"candidate_count\": 1,\n",
        "  \"temperature\": 0.5,\n",
        "}"
      ],
      "metadata": {
        "id": "lrHzJRVKU_Fm"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Configurações de segurança**"
      ],
      "metadata": {
        "id": "5G2vRwLoV01I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configurações de segurança das palavras ditas pelo chatbot\n",
        "safety_settings = {\n",
        "    \"HATE\": \"BLOCK_NONE\",\n",
        "    \"HARASSMENT\": \"BLOCK_NONE\",\n",
        "    \"SEXUAL\" : \"BLOCK_NONE\",\n",
        "    \"DANGEROUS\" : \"BLOCK_NONE\"\n",
        "}"
      ],
      "metadata": {
        "id": "Y_Yky2S0V5qD"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Inicializando o modelo**"
      ],
      "metadata": {
        "id": "iBp14veoXF5x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicilizando modelo gemini\n",
        "model = genai.GenerativeModel(model_name=\"gemini-1.0-pro\",\n",
        "                              generation_config=generation_config,\n",
        "                              safety_settings=safety_settings)"
      ],
      "metadata": {
        "id": "Bi9g1jgGXLH-"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Obetendo respostas do gemini**"
      ],
      "metadata": {
        "id": "q8Ys5hOTYchW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Gerando resposta da pergunta e guardando na variavel resposta\n",
        "response = model.generate_content(\"Que empresa criou o modelo de IA Gemini?\")\n",
        "response.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "P-4SyjEsYfLo",
        "outputId": "ef609ca9-f653-432c-b0ee-84b1773752f1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Google'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Criando o chatbot**"
      ],
      "metadata": {
        "id": "9JD56ZZAZaRW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Iniciando o chat começando com o historico vazio\n",
        "chat = model.start_chat(history=[])\n",
        "\n",
        "# Criando o prompt para pergunta do usuario\n",
        "prompt = input(\"Esperando sua pergunta: \")\n",
        "\n",
        "# Loop para o chat funcionar ate o usuario encerrar\n",
        "while prompt != \"fim\":\n",
        "  # Guardando mensagem enviada recebendo o valor da prompt\n",
        "  response = chat.send_message(prompt)\n",
        "  print(\"Resposta: \", response.text, '\\n')\n",
        "  prompt = input(\"Esperando sua pergunta: \")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nj-EqzBZemO",
        "outputId": "2d965c46-9405-4109-c4fa-2add76471f06"
      },
      "execution_count": 24,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Esperando sua pergunta: fim\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Melhorando a vizualização do chatbot**"
      ],
      "metadata": {
        "id": "NRu8BZO-cdI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Melhorando a visualização\n",
        "# Código disponível em https://ai.google.dev/tutorials/python_quickstart#import_packages\n",
        "import textwrap\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "# Definindo marcações\n",
        "def to_markdown(text):\n",
        "  text = text.replace('•', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n",
        "\n",
        "# Loop do historico sendo mostrado em markdown\n",
        "for message in chat.history:\n",
        "  display(to_markdown(f'**{message.role}**: {message.parts[0].text}'))\n",
        "  print('-------------------------------------------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "RQJOT1FNchnG",
        "outputId": "1aeb17d8-805a-4337-839a-d40e89b89885"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> **user**: Qual capital do Japão?"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> **model**: Tóquio"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> **user**: Meu primo nasceu nessa cidade, qual sua nacionalidade?"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> **model**: Japonesa"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> **user**: Quantos habitantes tem nesa cidade?"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> **model**: Aproximadamente 13.960.000 (em 2023)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}